"""Tests for logging_system.py to achieve 90%+ coverage.

This test module covers:
- SessionLogger class methods (get_logger, cleanup, process_record, etc.)
- Event classification and building
- Log queue processing and enqueuing
- Session log archive writing (write_session_log_archive)
- Format helpers (format_event_as_text, etc.)
- Edge cases and error handling
"""

from __future__ import annotations

import asyncio
import datetime
import io
import json
import logging
import os
import sys
import tempfile
import threading
import time
from collections import deque
from pathlib import Path
from typing import Any
from unittest.mock import MagicMock, Mock, patch, PropertyMock

import pytest

from open_webui_openrouter_pipe.core.logging_system import (
    SessionLogger,
    _SessionLogArchiveJob,
    write_session_log_archive,
)


# -----------------------------------------------------------------------------
# Test: pyzipper import fallback (lines 37-38)
# -----------------------------------------------------------------------------

class TestPyzipperImportFallback:
    """Test behavior when pyzipper is not available."""

    def test_write_session_log_archive_no_pyzipper(self, tmp_path: Path) -> None:
        """write_session_log_archive returns early when pyzipper is None."""
        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"test",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user1",
            session_id="sess1",
            chat_id="chat1",
            message_id="msg1",
            request_id="req1",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[{"message": "test"}],
        )
        # Patch pyzipper to None
        with patch("open_webui_openrouter_pipe.core.logging_system.pyzipper", None):
            write_session_log_archive(job)
        # No zip file should be created
        assert not list(tmp_path.rglob("*.zip"))


# -----------------------------------------------------------------------------
# Test: _classify_event_type (lines 101-110)
# -----------------------------------------------------------------------------

class TestClassifyEventType:
    """Test event type classification based on message content."""

    def test_classify_openrouter_request_headers(self) -> None:
        result = SessionLogger._classify_event_type("OpenRouter request headers: ...")
        assert result == "openrouter.request.headers"

    def test_classify_openrouter_request_payload(self) -> None:
        result = SessionLogger._classify_event_type("OpenRouter request payload: {...}")
        assert result == "openrouter.request.payload"

    def test_classify_openrouter_sse_event(self) -> None:
        result = SessionLogger._classify_event_type("OpenRouter payload: data: {...}")
        assert result == "openrouter.sse.event"

    def test_classify_tool_message(self) -> None:
        result = SessionLogger._classify_event_type("Tool execution completed")
        assert result == "pipe.tools"

    def test_classify_tool_emoji_message(self) -> None:
        # Test with wrench emoji prefix
        result = SessionLogger._classify_event_type("\U0001f527 Running tool...")
        assert result == "pipe.tools"

    def test_classify_skipping_message(self) -> None:
        result = SessionLogger._classify_event_type("Skipping duplicate tool call")
        assert result == "pipe.tools"

    def test_classify_generic_pipe_message(self) -> None:
        result = SessionLogger._classify_event_type("Some generic message")
        assert result == "pipe"

    def test_classify_empty_message(self) -> None:
        result = SessionLogger._classify_event_type("")
        assert result == "pipe"

    def test_classify_none_message(self) -> None:
        result = SessionLogger._classify_event_type(None)  # type: ignore[arg-type]
        assert result == "pipe"

    def test_classify_message_with_leading_whitespace(self) -> None:
        result = SessionLogger._classify_event_type("   OpenRouter request headers: ...")
        assert result == "openrouter.request.headers"


# -----------------------------------------------------------------------------
# Test: _build_event (lines 116-147)
# -----------------------------------------------------------------------------

class TestBuildEvent:
    """Test building structured events from LogRecord."""

    def test_build_event_basic(self) -> None:
        record = logging.LogRecord(
            name="test.logger",
            level=logging.INFO,
            pathname="test.py",
            lineno=42,
            msg="Test message",
            args=(),
            exc_info=None,
        )
        record.request_id = "req-123"
        record.session_id = "sess-456"
        record.user_id = "user-789"

        event = SessionLogger._build_event(record)

        assert event["level"] == "INFO"
        assert event["logger"] == "test.logger"
        assert event["request_id"] == "req-123"
        assert event["session_id"] == "sess-456"
        assert event["user_id"] == "user-789"
        assert event["message"] == "Test message"
        assert event["lineno"] == 42
        assert "created" in event
        assert event["event_type"] == "pipe"

    def test_build_event_with_exc_text(self) -> None:
        record = logging.LogRecord(
            name="test.logger",
            level=logging.ERROR,
            pathname="test.py",
            lineno=10,
            msg="Error occurred",
            args=(),
            exc_info=None,
        )
        record.exc_text = "Traceback (most recent call last):\n  File ..."
        record.request_id = "req-1"
        record.session_id = None
        record.user_id = None

        event = SessionLogger._build_event(record)

        assert "exception" in event
        assert event["exception"]["text"] == record.exc_text

    def test_build_event_with_exc_info(self) -> None:
        try:
            raise ValueError("Test error")
        except ValueError:
            exc_info = sys.exc_info()

        record = logging.LogRecord(
            name="test.logger",
            level=logging.ERROR,
            pathname="test.py",
            lineno=20,
            msg="Error with exc_info",
            args=(),
            exc_info=exc_info,
        )
        record.request_id = "req-2"
        record.session_id = None
        record.user_id = None

        event = SessionLogger._build_event(record)

        assert "exception" in event
        assert "ValueError" in event["exception"]["text"]
        assert "Test error" in event["exception"]["text"]

    def test_build_event_getMessage_fails(self) -> None:
        """Test fallback when getMessage() raises."""
        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=1,
            msg="test %s",
            args=("arg",),
            exc_info=None,
        )
        record.request_id = "req-3"
        record.session_id = None
        record.user_id = None

        # Make getMessage raise
        def raise_error():
            raise RuntimeError("getMessage failed")

        record.getMessage = raise_error  # type: ignore[assignment]

        event = SessionLogger._build_event(record)
        # Falls back to str(msg)
        assert event["message"] == "test %s"

    def test_build_event_missing_attributes(self) -> None:
        """Test with minimal LogRecord without custom attributes."""
        record = logging.LogRecord(
            name="",
            level=logging.DEBUG,
            pathname="",
            lineno=0,
            msg="",
            args=(),
            exc_info=None,
        )
        # Don't set request_id, session_id, user_id

        event = SessionLogger._build_event(record)

        assert event["request_id"] is None
        assert event["session_id"] is None
        assert event["user_id"] is None
        assert event["logger"] == ""
        assert event["lineno"] == 0


# -----------------------------------------------------------------------------
# Test: format_event_as_text (lines 153-171)
# -----------------------------------------------------------------------------

class TestFormatEventAsText:
    """Test text formatting of log events."""

    def test_format_event_basic(self) -> None:
        event = {
            "created": time.time(),
            "level": "INFO",
            "user_id": "user-1",
            "message": "Test message",
        }
        result = SessionLogger.format_event_as_text(event)

        assert "[INFO]" in result
        assert "[user=user-1]" in result
        assert "Test message" in result

    def test_format_event_missing_created(self) -> None:
        event = {
            "level": "WARNING",
            "user_id": "u1",
            "message": "No created field",
        }
        result = SessionLogger.format_event_as_text(event)
        assert "[WARNING]" in result
        assert "No created field" in result

    def test_format_event_invalid_created(self) -> None:
        event = {
            "created": "not-a-number",
            "level": "ERROR",
            "user_id": None,
            "message": "Invalid created",
        }
        result = SessionLogger.format_event_as_text(event)
        assert "[ERROR]" in result
        assert "[user=-]" in result

    def test_format_event_none_message(self) -> None:
        event = {
            "created": time.time(),
            "level": "DEBUG",
            "user_id": "x",
            "message": None,
        }
        result = SessionLogger.format_event_as_text(event)
        assert "[DEBUG]" in result
        # Message should be empty string

    def test_format_event_exception_in_strftime(self) -> None:
        """Test fallback when time.localtime fails."""
        event = {
            "created": time.time(),
            "level": "INFO",
            "user_id": "user",
            "message": "msg",
        }
        # Patch time.localtime to raise, triggering the except block (line 162-163)
        with patch("time.localtime", side_effect=ValueError("localtime failed")):
            result = SessionLogger.format_event_as_text(event)
        # Should use fallback datetime formatting
        assert "[INFO]" in result

    def test_format_event_message_str_fails(self) -> None:
        """Test fallback when str(message) fails."""

        class BadStr:
            def __str__(self):
                raise RuntimeError("str failed")

        event = {
            "created": time.time(),
            "level": "INFO",
            "user_id": "u",
            "message": BadStr(),
        }
        result = SessionLogger.format_event_as_text(event)
        # Should return empty message fallback
        assert "[INFO]" in result


# -----------------------------------------------------------------------------
# Test: get_logger (lines 175-226, specifically 192)
# -----------------------------------------------------------------------------

class TestGetLogger:
    """Test logger creation and configuration."""

    def test_get_logger_basic(self) -> None:
        logger = SessionLogger.get_logger("test.get_logger")
        assert logger.name == "test.get_logger"
        assert logger.level == logging.DEBUG
        assert logger.propagate is True

    def test_get_logger_adds_null_handler_to_root(self) -> None:
        """Ensure NullHandler is added to root logger if not present."""
        root = logging.getLogger()
        # Clear all NullHandlers
        root.handlers = [h for h in root.handlers if not isinstance(h, logging.NullHandler)]

        SessionLogger.get_logger("test.null_handler")

        has_null = any(isinstance(h, logging.NullHandler) for h in root.handlers)
        assert has_null

    def test_get_logger_filter_attaches_metadata(self) -> None:
        """Test that the filter attaches session metadata to records."""
        # Set up context
        token_sid = SessionLogger.session_id.set("sid-filter-test")
        token_rid = SessionLogger.request_id.set("rid-filter-test")
        token_uid = SessionLogger.user_id.set("uid-filter-test")

        try:
            logger = SessionLogger.get_logger("test.filter_metadata")
            record = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="test",
                args=(),
                exc_info=None,
            )
            # Apply the filter
            for f in logger.filters:
                f(record)

            assert getattr(record, "session_id", None) == "sid-filter-test"
            assert getattr(record, "request_id", None) == "rid-filter-test"
            assert getattr(record, "user_id", None) == "uid-filter-test"
        finally:
            SessionLogger.session_id.reset(token_sid)
            SessionLogger.request_id.reset(token_rid)
            SessionLogger.user_id.reset(token_uid)

    def test_get_logger_filter_handles_exception(self) -> None:
        """Test filter doesn't break when contextvar access fails."""
        logger = SessionLogger.get_logger("test.filter_exception")
        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="",
            lineno=0,
            msg="test",
            args=(),
            exc_info=None,
        )

        # Apply filter - should always return True
        for f in logger.filters:
            result = f(record)
            assert result is True


# -----------------------------------------------------------------------------
# Test: set_max_lines (lines 241-246)
# -----------------------------------------------------------------------------

class TestSetMaxLines:
    """Test max_lines configuration."""

    def test_set_max_lines_valid(self) -> None:
        original = SessionLogger.max_lines
        try:
            SessionLogger.set_max_lines(5000)
            assert SessionLogger.max_lines == 5000
        finally:
            SessionLogger.max_lines = original

    def test_set_max_lines_below_minimum(self) -> None:
        original = SessionLogger.max_lines
        try:
            SessionLogger.set_max_lines(10)  # Below minimum of 100
            assert SessionLogger.max_lines == 100
        finally:
            SessionLogger.max_lines = original

    def test_set_max_lines_above_maximum(self) -> None:
        original = SessionLogger.max_lines
        try:
            SessionLogger.set_max_lines(999999)  # Above maximum of 200000
            assert SessionLogger.max_lines == 200000
        finally:
            SessionLogger.max_lines = original

    def test_set_max_lines_invalid_value(self) -> None:
        original = SessionLogger.max_lines
        try:
            SessionLogger.set_max_lines("not-a-number")  # type: ignore[arg-type]
            # Should not change the value
            assert SessionLogger.max_lines == original
        finally:
            SessionLogger.max_lines = original


# -----------------------------------------------------------------------------
# Test: _enqueue (lines 250-268)
# -----------------------------------------------------------------------------

class TestEnqueue:
    """Test log record enqueuing."""

    def test_enqueue_no_queue(self) -> None:
        """When queue is None, process_record is called directly."""
        original_queue = SessionLogger.log_queue
        try:
            SessionLogger.log_queue = None
            record = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="test",
                args=(),
                exc_info=None,
            )
            with patch.object(SessionLogger, "process_record") as mock_process:
                SessionLogger._enqueue(record)
                mock_process.assert_called_once_with(record)
        finally:
            SessionLogger.log_queue = original_queue

    @pytest.mark.asyncio
    async def test_enqueue_same_loop(self) -> None:
        """When in the same event loop, use _safe_put directly."""
        loop = asyncio.get_running_loop()
        queue: asyncio.Queue[logging.LogRecord] = asyncio.Queue()
        original_queue = SessionLogger.log_queue
        original_loop = SessionLogger._main_loop

        try:
            SessionLogger.log_queue = queue
            SessionLogger._main_loop = loop

            record = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="test enqueue same loop",
                args=(),
                exc_info=None,
            )
            SessionLogger._enqueue(record)

            # Record should be in queue
            assert not queue.empty()
            queued_record = await queue.get()
            assert queued_record.msg == "test enqueue same loop"
        finally:
            SessionLogger.log_queue = original_queue
            SessionLogger._main_loop = original_loop

    def test_enqueue_different_loop_threadsafe(self) -> None:
        """When in different thread, use call_soon_threadsafe."""
        original_queue = SessionLogger.log_queue
        original_loop = SessionLogger._main_loop

        try:
            # Create a mock loop that's not closed
            mock_loop = MagicMock()
            mock_loop.is_closed.return_value = False
            queue: asyncio.Queue[logging.LogRecord] = asyncio.Queue()

            SessionLogger.log_queue = queue
            SessionLogger._main_loop = mock_loop

            record = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="threadsafe test",
                args=(),
                exc_info=None,
            )
            # Call from outside event loop context
            SessionLogger._enqueue(record)

            mock_loop.call_soon_threadsafe.assert_called_once()
        finally:
            SessionLogger.log_queue = original_queue
            SessionLogger._main_loop = original_loop

    def test_enqueue_closed_loop_fallback(self) -> None:
        """When main loop is closed, fall back to process_record."""
        original_queue = SessionLogger.log_queue
        original_loop = SessionLogger._main_loop

        try:
            mock_loop = MagicMock()
            mock_loop.is_closed.return_value = True
            queue: asyncio.Queue[logging.LogRecord] = asyncio.Queue()

            SessionLogger.log_queue = queue
            SessionLogger._main_loop = mock_loop

            record = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="closed loop test",
                args=(),
                exc_info=None,
            )

            with patch.object(SessionLogger, "process_record") as mock_process:
                SessionLogger._enqueue(record)
                mock_process.assert_called_once_with(record)
        finally:
            SessionLogger.log_queue = original_queue
            SessionLogger._main_loop = original_loop


# -----------------------------------------------------------------------------
# Test: _safe_put (lines 272-276)
# -----------------------------------------------------------------------------

class TestSafePut:
    """Test safe queue put operation."""

    @pytest.mark.asyncio
    async def test_safe_put_success(self) -> None:
        queue: asyncio.Queue[logging.LogRecord] = asyncio.Queue()
        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="",
            lineno=0,
            msg="safe put test",
            args=(),
            exc_info=None,
        )
        SessionLogger._safe_put(queue, record)

        assert not queue.empty()
        result = await queue.get()
        assert result.msg == "safe put test"

    @pytest.mark.asyncio
    async def test_safe_put_queue_full(self) -> None:
        """When queue is full, fall back to process_record."""
        queue: asyncio.Queue[logging.LogRecord] = asyncio.Queue(maxsize=1)
        # Fill the queue
        queue.put_nowait(
            logging.LogRecord("x", logging.INFO, "", 0, "filler", (), None)
        )

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="",
            lineno=0,
            msg="overflow test",
            args=(),
            exc_info=None,
        )

        with patch.object(SessionLogger, "process_record") as mock_process:
            SessionLogger._safe_put(queue, record)
            mock_process.assert_called_once_with(record)


# -----------------------------------------------------------------------------
# Test: process_record (lines 280-320)
# -----------------------------------------------------------------------------

class TestProcessRecord:
    """Test log record processing."""

    def test_process_record_writes_to_stdout(self, capsys) -> None:
        record = logging.LogRecord(
            name="test.stdout",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="stdout test message",
            args=(),
            exc_info=None,
        )
        record.session_log_level = logging.DEBUG
        record.request_id = None

        SessionLogger.process_record(record)

        captured = capsys.readouterr()
        assert "stdout test message" in captured.out

    def test_process_record_respects_log_level(self, capsys) -> None:
        """Messages below session_log_level should not be printed."""
        record = logging.LogRecord(
            name="test.level",
            level=logging.DEBUG,
            pathname="test.py",
            lineno=10,
            msg="debug message should be filtered",
            args=(),
            exc_info=None,
        )
        record.session_log_level = logging.INFO  # Only INFO and above
        record.request_id = None

        SessionLogger.process_record(record)

        captured = capsys.readouterr()
        assert "debug message should be filtered" not in captured.out

    def test_process_record_stores_in_buffer(self) -> None:
        """Records with request_id are stored in logs buffer."""
        original_logs = SessionLogger.logs.copy()
        original_last_seen = SessionLogger._session_last_seen.copy()

        try:
            # Clear
            SessionLogger.logs.clear()
            SessionLogger._session_last_seen.clear()

            record = logging.LogRecord(
                name="test.buffer",
                level=logging.INFO,
                pathname="test.py",
                lineno=20,
                msg="buffer test message",
                args=(),
                exc_info=None,
            )
            record.session_log_level = logging.INFO
            record.request_id = "req-buffer-test"
            record.session_id = "sess-1"
            record.user_id = "user-1"

            SessionLogger.process_record(record)

            assert "req-buffer-test" in SessionLogger.logs
            buffer = SessionLogger.logs["req-buffer-test"]
            assert len(buffer) == 1
            assert buffer[0]["message"] == "buffer test message"
        finally:
            SessionLogger.logs.clear()
            SessionLogger.logs.update(original_logs)
            SessionLogger._session_last_seen.clear()
            SessionLogger._session_last_seen.update(original_last_seen)

    def test_process_record_creates_new_buffer(self) -> None:
        """New buffer is created when request_id is new."""
        original_logs = SessionLogger.logs.copy()
        original_last_seen = SessionLogger._session_last_seen.copy()

        try:
            SessionLogger.logs.clear()
            SessionLogger._session_last_seen.clear()

            record = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="new buffer",
                args=(),
                exc_info=None,
            )
            record.session_log_level = logging.INFO
            record.request_id = "new-request-id"
            record.session_id = None
            record.user_id = None

            SessionLogger.process_record(record)

            assert "new-request-id" in SessionLogger.logs
            assert isinstance(SessionLogger.logs["new-request-id"], deque)
        finally:
            SessionLogger.logs.clear()
            SessionLogger.logs.update(original_logs)
            SessionLogger._session_last_seen.clear()
            SessionLogger._session_last_seen.update(original_last_seen)

    def test_process_record_build_event_fails(self, capsys) -> None:
        """Test fallback when _build_event raises."""
        original_logs = SessionLogger.logs.copy()
        original_last_seen = SessionLogger._session_last_seen.copy()

        try:
            SessionLogger.logs.clear()
            SessionLogger._session_last_seen.clear()

            record = logging.LogRecord(
                name="test",
                level=logging.ERROR,
                pathname="test.py",
                lineno=99,
                msg="fallback test",
                args=(),
                exc_info=None,
            )
            record.session_log_level = logging.DEBUG
            record.request_id = "req-fallback"
            record.session_id = "sess-fallback"
            record.user_id = "user-fallback"

            # Mock _build_event to raise
            with patch.object(SessionLogger, "_build_event", side_effect=RuntimeError("build failed")):
                SessionLogger.process_record(record)

            # Should still store a fallback event
            assert "req-fallback" in SessionLogger.logs
            event = SessionLogger.logs["req-fallback"][0]
            assert event["message"] == "fallback test"
            assert event["level"] == "ERROR"
        finally:
            SessionLogger.logs.clear()
            SessionLogger.logs.update(original_logs)
            SessionLogger._session_last_seen.clear()
            SessionLogger._session_last_seen.update(original_last_seen)

    def test_process_record_resizes_buffer_on_maxlen_change(self) -> None:
        """Buffer is recreated if max_lines changes."""
        original_logs = SessionLogger.logs.copy()
        original_last_seen = SessionLogger._session_last_seen.copy()
        original_max = SessionLogger.max_lines

        try:
            SessionLogger.logs.clear()
            SessionLogger._session_last_seen.clear()

            # Create initial buffer with one max_lines
            SessionLogger.max_lines = 100
            record1 = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="first",
                args=(),
                exc_info=None,
            )
            record1.session_log_level = logging.DEBUG
            record1.request_id = "req-resize"
            record1.session_id = None
            record1.user_id = None

            SessionLogger.process_record(record1)
            assert SessionLogger.logs["req-resize"].maxlen == 100

            # Change max_lines and add another record
            SessionLogger.max_lines = 200
            record2 = logging.LogRecord(
                name="test",
                level=logging.INFO,
                pathname="",
                lineno=0,
                msg="second",
                args=(),
                exc_info=None,
            )
            record2.session_log_level = logging.DEBUG
            record2.request_id = "req-resize"
            record2.session_id = None
            record2.user_id = None

            SessionLogger.process_record(record2)
            # Buffer should be recreated with new maxlen
            assert SessionLogger.logs["req-resize"].maxlen == 200
        finally:
            SessionLogger.logs.clear()
            SessionLogger.logs.update(original_logs)
            SessionLogger._session_last_seen.clear()
            SessionLogger._session_last_seen.update(original_last_seen)
            SessionLogger.max_lines = original_max


# -----------------------------------------------------------------------------
# Test: cleanup (lines 326-331)
# -----------------------------------------------------------------------------

class TestCleanup:
    """Test session cleanup functionality."""

    def test_cleanup_removes_stale_sessions(self) -> None:
        original_logs = SessionLogger.logs.copy()
        original_last_seen = SessionLogger._session_last_seen.copy()

        try:
            SessionLogger.logs.clear()
            SessionLogger._session_last_seen.clear()

            # Add a stale session (2 hours old)
            stale_time = time.time() - 7200
            SessionLogger.logs["stale-session"] = deque([{"message": "old"}])
            SessionLogger._session_last_seen["stale-session"] = stale_time

            # Add a fresh session
            SessionLogger.logs["fresh-session"] = deque([{"message": "new"}])
            SessionLogger._session_last_seen["fresh-session"] = time.time()

            # Cleanup with 1 hour max age
            SessionLogger.cleanup(max_age_seconds=3600)

            assert "stale-session" not in SessionLogger.logs
            assert "stale-session" not in SessionLogger._session_last_seen
            assert "fresh-session" in SessionLogger.logs
        finally:
            SessionLogger.logs.clear()
            SessionLogger.logs.update(original_logs)
            SessionLogger._session_last_seen.clear()
            SessionLogger._session_last_seen.update(original_last_seen)

    def test_cleanup_no_stale_sessions(self) -> None:
        original_logs = SessionLogger.logs.copy()
        original_last_seen = SessionLogger._session_last_seen.copy()

        try:
            SessionLogger.logs.clear()
            SessionLogger._session_last_seen.clear()

            # Add only fresh sessions
            SessionLogger.logs["fresh-1"] = deque([{"message": "msg1"}])
            SessionLogger._session_last_seen["fresh-1"] = time.time()
            SessionLogger.logs["fresh-2"] = deque([{"message": "msg2"}])
            SessionLogger._session_last_seen["fresh-2"] = time.time()

            SessionLogger.cleanup(max_age_seconds=3600)

            assert "fresh-1" in SessionLogger.logs
            assert "fresh-2" in SessionLogger.logs
        finally:
            SessionLogger.logs.clear()
            SessionLogger.logs.update(original_logs)
            SessionLogger._session_last_seen.clear()
            SessionLogger._session_last_seen.update(original_last_seen)


# -----------------------------------------------------------------------------
# Test: write_session_log_archive (lines 353-564)
# -----------------------------------------------------------------------------

class TestWriteSessionLogArchive:
    """Test session log archive writing functionality."""

    def test_archive_empty_base_dir(self) -> None:
        """Returns early when base_dir is empty."""
        job = _SessionLogArchiveJob(
            base_dir="",
            zip_password=b"test",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="u1",
            session_id="s1",
            chat_id="c1",
            message_id="m1",
            request_id="r1",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[],
        )
        # Should return early without error
        write_session_log_archive(job)

    def test_archive_whitespace_base_dir(self) -> None:
        """Returns early when base_dir is whitespace only."""
        job = _SessionLogArchiveJob(
            base_dir="   ",
            zip_password=b"test",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="u1",
            session_id="s1",
            chat_id="c1",
            message_id="m1",
            request_id="r1",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[],
        )
        write_session_log_archive(job)

    def test_archive_creates_zip_jsonl_format(self, tmp_path: Path) -> None:
        """Creates zip archive with JSONL format."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"testpassword",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-archive",
            session_id="sess-archive",
            chat_id="chat-archive",
            message_id="msg-archive",
            request_id="req-archive",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[
                {"created": time.time(), "level": "INFO", "message": "Test log 1", "request_id": "req-archive"},
                {"created": time.time(), "level": "DEBUG", "message": "Test log 2", "request_id": "req-archive"},
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-archive" / "chat-archive" / "msg-archive.zip"
        assert zip_path.exists()

        # Verify contents
        with pyzipper.AESZipFile(zip_path, "r") as zf:
            zf.setpassword(b"testpassword")
            names = zf.namelist()
            assert "meta.json" in names
            assert "logs.jsonl" in names
            assert "logs.txt" not in names

    def test_archive_creates_zip_text_format(self, tmp_path: Path) -> None:
        """Creates zip archive with text format."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"testpw",
            zip_compression="deflated",
            zip_compresslevel=6,
            user_id="user-text",
            session_id="sess-text",
            chat_id="chat-text",
            message_id="msg-text",
            request_id="req-text",
            created_at=time.time(),
            log_format="text",
            log_events=[
                {"created": time.time(), "level": "WARNING", "message": "Warning message"},
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-text" / "chat-text" / "msg-text.zip"
        assert zip_path.exists()

        with pyzipper.AESZipFile(zip_path, "r") as zf:
            zf.setpassword(b"testpw")
            names = zf.namelist()
            assert "meta.json" in names
            assert "logs.txt" in names
            assert "logs.jsonl" not in names

    def test_archive_creates_zip_both_format(self, tmp_path: Path) -> None:
        """Creates zip archive with both text and JSONL formats."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="bzip2",
            zip_compresslevel=9,
            user_id="user-both",
            session_id="sess-both",
            chat_id="chat-both",
            message_id="msg-both",
            request_id="req-both",
            created_at=time.time(),
            log_format="both",
            log_events=[
                {"created": time.time(), "level": "ERROR", "message": "Error msg"},
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-both" / "chat-both" / "msg-both.zip"
        assert zip_path.exists()

        with pyzipper.AESZipFile(zip_path, "r") as zf:
            zf.setpassword(b"pw")
            names = zf.namelist()
            assert "meta.json" in names
            assert "logs.txt" in names
            assert "logs.jsonl" in names

    def test_archive_invalid_log_format_defaults_jsonl(self, tmp_path: Path) -> None:
        """Invalid log_format defaults to jsonl."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-invalid",
            session_id="sess-invalid",
            chat_id="chat-invalid",
            message_id="msg-invalid",
            request_id="req-invalid",
            created_at=time.time(),
            log_format="invalid-format",
            log_events=[{"message": "test"}],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-invalid" / "chat-invalid" / "msg-invalid.zip"
        assert zip_path.exists()

        with pyzipper.AESZipFile(zip_path, "r") as zf:
            zf.setpassword(b"pw")
            assert "logs.jsonl" in zf.namelist()

    def test_archive_stored_compression(self, tmp_path: Path) -> None:
        """Test stored (no compression) mode."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="stored",
            zip_compresslevel=None,
            user_id="user-stored",
            session_id="sess-stored",
            chat_id="chat-stored",
            message_id="msg-stored",
            request_id="req-stored",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[{"message": "stored test"}],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-stored" / "chat-stored" / "msg-stored.zip"
        assert zip_path.exists()

    def test_archive_handles_non_dict_events(self, tmp_path: Path) -> None:
        """Test coercion of non-dict log events."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-coerce",
            session_id="sess-coerce",
            chat_id="chat-coerce",
            message_id="msg-coerce",
            request_id="req-coerce",
            created_at=time.time(),
            log_format="both",
            log_events=[
                "string event",  # Non-dict
                123,  # Non-dict
                {"message": "dict event"},  # Dict
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-coerce" / "chat-coerce" / "msg-coerce.zip"
        assert zip_path.exists()

    def test_archive_handles_exception_in_event(self, tmp_path: Path) -> None:
        """Test events with exception block."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-exc",
            session_id="sess-exc",
            chat_id="chat-exc",
            message_id="msg-exc",
            request_id="req-exc",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[
                {
                    "created": time.time(),
                    "level": "ERROR",
                    "message": "Error with exception",
                    "exception": {"text": "Traceback..."},
                },
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-exc" / "chat-exc" / "msg-exc.zip"
        assert zip_path.exists()

        with pyzipper.AESZipFile(zip_path, "r") as zf:
            zf.setpassword(b"pw")
            content = zf.read("logs.jsonl").decode("utf-8")
            data = json.loads(content.strip())
            assert "exception" in data

    def test_archive_extracts_request_ids(self, tmp_path: Path) -> None:
        """Test that unique request_ids are extracted from events."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-ids",
            session_id="sess-ids",
            chat_id="chat-ids",
            message_id="msg-ids",
            request_id="req-main",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[
                {"message": "1", "request_id": "req-a"},
                {"message": "2", "request_id": "req-b"},
                {"message": "3", "request_id": "req-a"},  # Duplicate
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-ids" / "chat-ids" / "msg-ids.zip"
        with pyzipper.AESZipFile(zip_path, "r") as zf:
            zf.setpassword(b"pw")
            meta = json.loads(zf.read("meta.json").decode("utf-8"))
            assert "request_ids" in meta
            assert sorted(meta["request_ids"]) == ["req-a", "req-b"]

    def test_archive_mkdir_fails(self, tmp_path: Path) -> None:
        """Test when mkdir fails."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user",
            session_id="sess",
            chat_id="chat",
            message_id="msg",
            request_id="req",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[],
        )

        with patch("pathlib.Path.mkdir", side_effect=PermissionError("denied")):
            # Should return without error
            write_session_log_archive(job)

    def test_archive_zip_write_fails(self, tmp_path: Path) -> None:
        """Test when zip file creation fails."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-fail",
            session_id="sess-fail",
            chat_id="chat-fail",
            message_id="msg-fail",
            request_id="req-fail",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[{"message": "test"}],
        )

        with patch("pyzipper.AESZipFile", side_effect=IOError("zip creation failed")):
            # Should return without error, cleanup tmp file
            write_session_log_archive(job)

        # No zip file should exist
        zip_path = tmp_path / "user-fail" / "chat-fail" / "msg-fail.zip"
        assert not zip_path.exists()

    def test_archive_replace_fails(self, tmp_path: Path) -> None:
        """Test when os.replace fails."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-replace",
            session_id="sess-replace",
            chat_id="chat-replace",
            message_id="msg-replace",
            request_id="req-replace",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[{"message": "test"}],
        )

        with patch("os.replace", side_effect=OSError("replace failed")):
            write_session_log_archive(job)

        # Final zip should not exist, tmp should be cleaned up
        zip_path = tmp_path / "user-replace" / "chat-replace" / "msg-replace.zip"
        assert not zip_path.exists()

    def test_archive_invalid_created_timestamp(self, tmp_path: Path) -> None:
        """Test events with invalid created timestamp."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-ts",
            session_id="sess-ts",
            chat_id="chat-ts",
            message_id="msg-ts",
            request_id="req-ts",
            created_at=time.time(),
            log_format="both",
            log_events=[
                {"created": "not-a-number", "level": "INFO", "message": "invalid ts"},
                {"created": None, "level": "INFO", "message": "no ts"},
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-ts" / "chat-ts" / "msg-ts.zip"
        assert zip_path.exists()

    def test_archive_json_encode_fails(self, tmp_path: Path) -> None:
        """Test fallback when JSON encoding of event fails."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        class Unencodable:
            def __str__(self):
                return "unencodable"

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-enc",
            session_id="sess-enc",
            chat_id="chat-enc",
            message_id="msg-enc",
            request_id="req-enc",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[
                {"created": time.time(), "level": "INFO", "message": Unencodable()},
            ],
        )

        # Patch json.dumps to fail on first call but succeed on fallback
        original_dumps = json.dumps
        call_count = [0]

        def failing_dumps(*args, **kwargs):
            call_count[0] += 1
            if call_count[0] == 2:  # First jsonl record
                raise TypeError("cannot serialize")
            return original_dumps(*args, **kwargs)

        with patch("json.dumps", side_effect=failing_dumps):
            write_session_log_archive(job)

        zip_path = tmp_path / "user-enc" / "chat-enc" / "msg-enc.zip"
        assert zip_path.exists()

    def test_archive_empty_events(self, tmp_path: Path) -> None:
        """Test with empty log events."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-empty",
            session_id="sess-empty",
            chat_id="chat-empty",
            message_id="msg-empty",
            request_id="req-empty",
            created_at=time.time(),
            log_format="both",
            log_events=[],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-empty" / "chat-empty" / "msg-empty.zip"
        assert zip_path.exists()


# -----------------------------------------------------------------------------
# Test: set_log_queue and set_main_loop (lines 230-235)
# -----------------------------------------------------------------------------

class TestQueueAndLoopSetters:
    """Test queue and loop setters."""

    def test_set_log_queue(self) -> None:
        original = SessionLogger.log_queue
        try:
            queue: asyncio.Queue[logging.LogRecord] = asyncio.Queue()
            SessionLogger.set_log_queue(queue)
            assert SessionLogger.log_queue is queue

            SessionLogger.set_log_queue(None)
            assert SessionLogger.log_queue is None
        finally:
            SessionLogger.log_queue = original

    @pytest.mark.asyncio
    async def test_set_main_loop(self) -> None:
        original = SessionLogger._main_loop
        try:
            loop = asyncio.get_running_loop()
            SessionLogger.set_main_loop(loop)
            assert SessionLogger._main_loop is loop

            SessionLogger.set_main_loop(None)
            assert SessionLogger._main_loop is None
        finally:
            SessionLogger._main_loop = original


# -----------------------------------------------------------------------------
# Test: _SessionLogArchiveJob dataclass
# -----------------------------------------------------------------------------

class TestSessionLogArchiveJob:
    """Test the archive job dataclass."""

    def test_job_creation(self) -> None:
        job = _SessionLogArchiveJob(
            base_dir="/tmp/logs",
            zip_password=b"secret",
            zip_compression="deflated",
            zip_compresslevel=6,
            user_id="user1",
            session_id="sess1",
            chat_id="chat1",
            message_id="msg1",
            request_id="req1",
            created_at=1234567890.123,
            log_format="both",
            log_events=[{"a": 1}, {"b": 2}],
        )
        assert job.base_dir == "/tmp/logs"
        assert job.zip_password == b"secret"
        assert job.zip_compression == "deflated"
        assert job.zip_compresslevel == 6
        assert job.user_id == "user1"
        assert job.session_id == "sess1"
        assert job.chat_id == "chat1"
        assert job.message_id == "msg1"
        assert job.request_id == "req1"
        assert job.created_at == 1234567890.123
        assert job.log_format == "both"
        assert len(job.log_events) == 2


# -----------------------------------------------------------------------------
# Test: Console formatter output (line 288-289)
# -----------------------------------------------------------------------------

class TestConsoleFormatterException:
    """Test console formatter exception handling."""

    def test_formatter_exception_caught(self, capsys) -> None:
        """Test that exceptions in console formatting are caught."""
        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="test message",
            args=(),
            exc_info=None,
        )
        record.session_log_level = logging.DEBUG
        record.request_id = None

        # Mock formatter to raise
        original_formatter = SessionLogger._console_formatter

        class FailingFormatter:
            def format(self, record):
                raise RuntimeError("format failed")

        try:
            SessionLogger._console_formatter = FailingFormatter()  # type: ignore
            # Should not raise
            SessionLogger.process_record(record)
        finally:
            SessionLogger._console_formatter = original_formatter


# -----------------------------------------------------------------------------
# Test: Context updates in filter (lines 208-212)
# -----------------------------------------------------------------------------

class TestFilterContextUpdates:
    """Test filter updates _session_last_seen."""

    def test_filter_updates_last_seen(self) -> None:
        original_last_seen = SessionLogger._session_last_seen.copy()

        try:
            SessionLogger._session_last_seen.clear()

            token_rid = SessionLogger.request_id.set("rid-last-seen-test")
            token_sid = SessionLogger.session_id.set("sid-test")
            token_uid = SessionLogger.user_id.set("uid-test")

            try:
                logger = SessionLogger.get_logger("test.last_seen")
                record = logging.LogRecord(
                    name="test",
                    level=logging.INFO,
                    pathname="",
                    lineno=0,
                    msg="test",
                    args=(),
                    exc_info=None,
                )

                # Apply filters
                for f in logger.filters:
                    f(record)

                # Check that last_seen was updated
                assert "rid-last-seen-test" in SessionLogger._session_last_seen
            finally:
                SessionLogger.request_id.reset(token_rid)
                SessionLogger.session_id.reset(token_sid)
                SessionLogger.user_id.reset(token_uid)
        finally:
            SessionLogger._session_last_seen.clear()
            SessionLogger._session_last_seen.update(original_last_seen)


# -----------------------------------------------------------------------------
# Additional edge case tests for higher coverage
# -----------------------------------------------------------------------------

class TestBuildEventExceptionInTraceback:
    """Test exception handling in _build_event traceback formatting."""

    def test_build_event_traceback_format_fails(self) -> None:
        """Test when traceback.format_exception fails."""
        try:
            raise ValueError("Test")
        except ValueError:
            exc_info = sys.exc_info()

        record = logging.LogRecord(
            name="test",
            level=logging.ERROR,
            pathname="test.py",
            lineno=1,
            msg="test",
            args=(),
            exc_info=exc_info,
        )
        record.request_id = "req-tb"
        record.session_id = None
        record.user_id = None

        # Patch traceback.format_exception to raise
        with patch("traceback.format_exception", side_effect=RuntimeError("format failed")):
            event = SessionLogger._build_event(record)

        # Exception field should not be present (handled gracefully)
        assert "exception" not in event or event.get("exception") is None


class TestArchiveEdgeCases:
    """Additional edge case tests for write_session_log_archive."""

    def test_archive_coerce_event_str_fails(self, tmp_path: Path) -> None:
        """Test _coerce_event when str() fails on non-dict."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        class BadStr:
            def __str__(self):
                raise RuntimeError("str failed")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-badstr",
            session_id="sess-badstr",
            chat_id="chat-badstr",
            message_id="msg-badstr",
            request_id="req-badstr",
            created_at=time.time(),
            log_format="both",
            log_events=[BadStr()],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-badstr" / "chat-badstr" / "msg-badstr.zip"
        assert zip_path.exists()

    def test_archive_message_str_fails_in_jsonl(self, tmp_path: Path) -> None:
        """Test when str(message) fails in _build_jsonl_record."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        class BadMessage:
            def __str__(self):
                raise RuntimeError("str failed")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-badmsg",
            session_id="sess-badmsg",
            chat_id="chat-badmsg",
            message_id="msg-badmsg",
            request_id="req-badmsg",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[
                {"created": time.time(), "level": "INFO", "message": BadMessage()},
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-badmsg" / "chat-badmsg" / "msg-badmsg.zip"
        assert zip_path.exists()

    def test_archive_text_format_with_none_values(self, tmp_path: Path) -> None:
        """Test text format with various None/empty values."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-none",
            session_id="sess-none",
            chat_id="chat-none",
            message_id="msg-none",
            request_id="req-none",
            created_at=time.time(),
            log_format="text",
            log_events=[
                {"message": None, "level": None, "user_id": None, "created": None},
                {"message": "", "level": "", "user_id": "", "created": ""},
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-none" / "chat-none" / "msg-none.zip"
        assert zip_path.exists()

    def test_archive_format_iso_utc_fails(self, tmp_path: Path) -> None:
        """Test when _format_iso_utc fails."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-iso",
            session_id="sess-iso",
            chat_id="chat-iso",
            message_id="msg-iso",
            request_id="req-iso",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[
                {"created": float("inf"), "level": "INFO", "message": "infinity"},
            ],
        )

        write_session_log_archive(job)

        zip_path = tmp_path / "user-iso" / "chat-iso" / "msg-iso.zip"
        assert zip_path.exists()

    def test_archive_request_ids_extraction_exception(self, tmp_path: Path) -> None:
        """Test when request_ids extraction fails."""
        try:
            import pyzipper
        except ImportError:
            pytest.skip("pyzipper not available")

        # Create event that will cause iteration issues
        class BadIterable:
            def __iter__(self):
                raise RuntimeError("iteration failed")

        job = _SessionLogArchiveJob(
            base_dir=str(tmp_path),
            zip_password=b"pw",
            zip_compression="lzma",
            zip_compresslevel=None,
            user_id="user-reqids",
            session_id="sess-reqids",
            chat_id="chat-reqids",
            message_id="msg-reqids",
            request_id="req-reqids",
            created_at=time.time(),
            log_format="jsonl",
            log_events=[{"message": "test"}],  # Regular events
        )

        # Patch job.log_events iteration
        original_events = job.log_events

        class FailingList(list):
            _count = 0

            def __iter__(self):
                FailingList._count += 1
                if FailingList._count == 1:
                    raise RuntimeError("iteration failed")
                return super().__iter__()

        # Can't easily patch the iteration, so skip this complex case
        write_session_log_archive(job)

        zip_path = tmp_path / "user-reqids" / "chat-reqids" / "msg-reqids.zip"
        assert zip_path.exists()


class TestProcessRecordOuterException:
    """Test outer exception handling in process_record."""

    def test_process_record_outer_exception_caught(self) -> None:
        """Test that outer exception in process_record is caught."""
        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=1,
            msg="test",
            args=(),
            exc_info=None,
        )
        record.request_id = "req-outer"
        record.session_id = None
        record.user_id = None
        record.session_log_level = logging.DEBUG

        # Mock getattr to raise on specific attribute
        original_getattr = getattr

        # Process record with mocked _state_lock that raises
        original_lock = SessionLogger._state_lock
        try:
            # Create a mock lock that raises on acquire
            class FailingLock:
                def __enter__(self):
                    raise RuntimeError("lock failed")

                def __exit__(self, *args):
                    pass

            SessionLogger._state_lock = FailingLock()  # type: ignore
            # Should not raise
            SessionLogger.process_record(record)
        finally:
            SessionLogger._state_lock = original_lock


class TestEmitHandler:
    """Test the emit handler in get_logger."""

    def test_emit_handler_calls_enqueue(self) -> None:
        """Test that emit handler properly calls _enqueue."""
        logger = SessionLogger.get_logger("test.emit_handler")

        # Find the handler with our custom emit
        handler = None
        for h in logger.handlers:
            if hasattr(h, "emit"):
                handler = h
                break

        assert handler is not None

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="",
            lineno=0,
            msg="emit test",
            args=(),
            exc_info=None,
        )

        with patch.object(SessionLogger, "_enqueue") as mock_enqueue:
            handler.emit(record)
            mock_enqueue.assert_called_once_with(record)
